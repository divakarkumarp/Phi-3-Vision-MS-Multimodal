# Phi-3-Vision-Microsoft-Multimodal

Microsoft Phi-3 Vision-the first Multimodal model By Microsoft, a multimodal model that brings together language and vision capabilities. the multimodal version comes with 128K context length (in tokens) it can support. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning and direct preference optimization to ensure precise instruction adherence and robust safety measures. 

[Demo with HuggingfaceðŸ¤—](https://github.com/divakarkumarp/Phi-3-Vision-MS-Multimodal/blob/main/Phi_3_vision_128k_instruct.ipynb)

![image](https://github.com/divakarkumarp/Phi-3-Vision-MS-Multimodal/assets/32620288/28e3b588-64d1-423e-881e-8e59384204bd)
